{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Sentiment Analysis for Enhanced Brand Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Objectives\n",
    "\n",
    "1. **Identify Brand Sentiment:**  The primary objective is to  leverage Natural Language Processing to categorize the emotions expressed in tweets directed at the brand.  This will involve classifying tweets as positive, negative, or neutral sentiment.\n",
    "\n",
    "2. **Understand Customer Emotions:**  By analyzing the emotions expressed in tweets  beyond just positive or negative, we aim to gain a deeper understanding of the specific emotions customers associate with the brand.  This could include happiness, sadness, anger, frustration, or excitement.\n",
    "\n",
    "3. **Actionable Insights:**  The final objective is to translate the sentiment analysis results into actionable insights for the branding team.  This could involve identifying recurring themes in negative tweets, pinpointing triggers for positive brand emotions, or highlighting areas where brand messaging can be improved to evoke desired customer emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer,TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and use encoding for the special characters\n",
    "data = pd.read_csv('judge-1377884607_tweet_product_company.csv',encoding='unicode_escape')\n",
    "# Preview top 5\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Data Understanding\n",
    "\n",
    "The provided dataset from data.world: https://data.world/crowdflower/brands-and-product-emotions offers valuable columns for sentiment analysis in branding:\n",
    "\n",
    "1. tweet_text: This column contains the actual text of the tweet, allowing for analysis of the sentiment expressed within the content itself.\n",
    "\n",
    "2. emotion_in_tweet_is_directed_at: This column identifies whether the expressed emotion is directed at a brand or product. This allows for targeted sentiment analysis specific to the brand's performance.\n",
    "\n",
    "\n",
    "3. is_there_an_emotion_directed_at_a_brand_or_product(**target variable**): This binary column provides a quick indicator of brand-related sentiment, enabling efficient initial filtering of relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 'tweet_text' to 'text'\n",
    "data = data.rename(columns={'tweet_text': 'text'})\n",
    "# Rename column 'emotion_in_tweet_is_directed_at' to 'target'\n",
    "data = data.rename(columns={'emotion_in_tweet_is_directed_at': 'target'})\n",
    "# Rename column 'is_there_an_emotion_directed_at_a_brand_or_product' to 'emotion'\n",
    "data = data.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a replace any target brand with the keyword using .replace()\n",
    "data['target'] = data['target'].str.replace(\"['Google','Other Google product or service']\", \"Google\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"iPad or iPhone App\", \"Apple\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace('Andriod App', \"Andriod\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"iPad\", \"Apple\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"iPhone\", \"Apple\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"Other Google product or service\", \"Google\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"Android App\", \"Android\", case=False, regex=False)\n",
    "data['target'] = data['target'].str.replace(\"Other Apple product or service\", \"Android\", case=False, regex=False)\n",
    "# Replace the no emotion toward brand or product to no emotion\n",
    "data['emotion'] = data['emotion'].str.replace(\"No emotion toward brand or product\", \"No emotion\", case=False, regex=False)\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"Undetermined\" in column: 'target'\n",
    "data = data.fillna({'target': \"Undetermined\"})\n",
    "# Drop the missing value in text\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "- The functions and its logic will be created first however data preprocessing will be done after the data split in order to regulate data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean the text\n",
    "def clean_text(text):\n",
    "    #TweetTokenizer also puts each punctuation as it's own token\n",
    "    no_handle = tweet_tknzr.tokenize(text)\n",
    "    #Join the list of non-handle tokens back together\n",
    "    text = \" \".join(no_handle) \n",
    "    # Remove the punctuation\n",
    "    text = re.sub(r'[^\\w\\s]',\"\",text)\n",
    "    # Remove the @ mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    # Remove \n",
    "    text = re.sub(r'&[a-z]+;', '', text)\n",
    "    #TweetTokenizer also puts each punctuation as it's own token\n",
    "    no_handle = tweet_tknzr.tokenize(text)\n",
    "    # Remove keyword link\n",
    "    text = re.sub(r\"\\blink\\b\", \" \", text)\n",
    "    # Remove keyword video\n",
    "    text = re.sub(r\"\\bvideo\\b\", \" \", text)\n",
    "    # Remove www. and .com\n",
    "    text = re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", \" \", text)\n",
    "    # Remove keyword \"sxsx\"\n",
    "    text = re.sub(r\"\\bsxsw\\b\", \" \", text)\n",
    "    # Remove keyword \"SXSW\"\n",
    "    text = re.sub(r\"\\bSXSW\\b\", \" \", text)\n",
    "    # Remove keyword sxtx\n",
    "    text = re.sub(r\"\\sxtx\\b\", \" \", text)\n",
    "    # Remove the # symbol\n",
    "    text = re.sub(r'#','', text)\n",
    "    # Removing RT\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    # Removing hyperlink\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    # Remove Special Characters\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\\ *(?:[^\\x00-\\x7F]|)*\", \" \", text)\n",
    "    # Remove curly brackets\n",
    "    text = re.sub(r'{.+?}', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove leftover numbers \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    #Lower all text\n",
    "    text = text.lower()\n",
    "    # Remove stop words and common Twitter jargon \n",
    "    stop_words = stopwords.words('english') + ['rt', 'amp']\n",
    "    # Remove empty strings after cleaning\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Remove empty strings after cleaning \n",
    "    text = ' '.join(word for word in text.split() if word)\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'text': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target into binary\n",
    "dict_target = {'No emotion':0, \n",
    "             'Positive emotion':1,\n",
    "             'Negative emotion':0,\n",
    "             \"I can't tell\": 0}\n",
    "data['emotion'] = data['emotion'].map(dict_target)\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
